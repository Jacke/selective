\section{Free selective functors}\label{sec-free}

Free construction with examples

\subsection{Free construction}\label{sec-free-construction}

...

\subsubsection{\textbf{Example: Teletype}}

To illustrate how the free selective construction can be used, we implement the
classical example of the Teletype DSL.

The \hs{TeletypeF} datatype has two constructors, representing the commands of the
Teletype interface:

\begin{minted}[xleftmargin=10pt]{haskell}
data Teletype a = GetLine (String -> a)
                | PutStrLn String a
    deriving Functor
\end{minted}

We embed these commands into the free selective with the following two combinators,
mimicking Haskell Prelude's IO API:

\begin{minted}[xleftmargin=10pt]{haskell}
getLine :: Select Teletype String
getLine = liftSelect (GetLine id)

putStrLn:: Select Teletype ()
putStrLn s = liftSelect (PutStrLn s ())
\end{minted}

By reimplement the \hs{pingPongS} example from the section \ref{sec-intro}
in terms of the free selective construction:

\begin{minted}[xleftmargin=10pt]{haskell}
pingPongS :: Select Teletype ()
pingPongS = whenS (fmap (=="ping") getLine) (putStrLn "pong")
\end{minted}

Once we have embedded the \hs{pingPongS} program into the free selective datatype,
we have access to the machinery allowing for static analysis of its effects:

\begin{minted}[xleftmargin=10pt]{haskell}
ghci> getEffects pingPong
[GetLine,PutStrLn pong]
\end{minted}

The \hs{getEffects} function of type \hs{Functor f => Select f a -> [f ()]}
returns a list of all effects of a free selective computations. In the specific case of
the Teletype functor, we get a list of all commands that a computations has called.
Internally, the \hs{getEffects} function interprets a free selective computation
in the \hs{Over} functor (see section~\ref{sec-instances}).

We can interpret Teletype programs in any other \hs{Selective} by means of the
\hs{runSelect} function, by providing a \emph{natural transformation} \hs{forall a. f a -> g a}, which gives an interpretation of the commands of
\hs{f} (specifically, \hs{Teletype}) in terms of \hs{g}. A natural example of such a
transformation would be an interpretation in the \hs{IO} monad:

\begin{minted}[xleftmargin=10pt]{haskell}
inIO :: Teletype a -> IO a
inIO (GetLine t)    = t <$> Prelude.getLine
inIO (PutStrLn s x) = Prelude.putStrLn s *> pure x
\end{minted}

\subsection{Build systems, freely}

...

\subsection{Analysis and simulation of processor instructions}

The methodology of building effectful computations with free constructions such
as free~\cite{free-monads} and freer~\cite{freer-monads} monads and free
applicatives~\cite{free-applicatives} is a widespread in the functional programming community.
It allows to focus on the internal aspects of the effect under consideration and receive the
desired applicative/monadic structure of the computation~\emph{for free}, i.e. without the need
to construct~\hs{Applicative}/~\hs{Monad} instances and proving the laws.

In the ``free-structure'' methodology, the essence of an effect is a datatype which encodes
the ``commands''which the effect provides. This datatype acts as a deep embedding of the effect's
interface. THis datatype must only have enough structure to be a~\hs{Functor}. The purpose of
the free constructions is then to build on this functor a richer structure, which would have
an instance of Applicative/Selective/Monad.

In this section, we demonstrate how we can use free selective functors to construct an
effect which can be used for effectively describing the semantics of a simple instruction set
architecture. The features of free selective functors will allow for multiple distinct
interpretations of the same semantics, such as~\emph{static} dependency analysis
and~\emph{dynamic} simulation.

\subsubsection{Embedding}

We will represent the semantics of instruction in terms of the following datatype:

\begin{minted}[xleftmargin=10pt]{haskell}
type ISA a = Select RW a
\end{minted}

Here, \hs{Select} is the free selective functor defined earlier in this section.
We apply the \hs{Select} type constructor to the \hs{RW} datatype, which is the
functor we build our free construction on:

\begin{minted}[xleftmargin=10pt]{haskell}
data RW k v a = R k             (v -> a)
              | W k (ISA k v v) (v -> a)
    deriving Functor
\end{minted}

The effect we require comprises two commands. We need to have an ability to (1)
\emph{read} a value associated with a key and, (2) given a computation which produces a value,
\emph{write} its result into the store. Here, the second argument of the \hs{W} constructor
This exact structure of the definition is required for accommodating a pattern that
frequently occurs in instruction semantics: often we read a value from a location
(register/memory), do something with the value and then write it into a different location.
If we had the type of \hs{W} to be \hs{k -> v -> (v -> a)}, i.e. required the value to be pure,
we would not be able to get away from using monadic bind/join. Additionally, we want the write
operation to not just write the value and return \hs{()}, but to return the just written value
back, so it somehow used in the context; such a generosity of the write command not consuming
its arguments will be useful to avoid creating more data dependencies than necessary.

We introduce two convenience combinators, which \emph{lift} the data constructors
of the \hs{RW} datatype into the free selective, thus making them directly usable in
the definitions of instruction semantics:

\begin{minted}[xleftmargin=10pt]{haskell}
read :: Location -> ISA Value
read k = liftSelect (R k id)

write :: Location -> ISA Value -> ISA Value
write k p = p *> liftSelect (W k p id)
\end{minted}

Whereas the \hs{read} combinator is exactly the lifted \hs{R} data constructor, the \hs{write}'s implementation deserves attention, since it deviates from the trivial lifting of
the \hs{W} data constructor. It evaluates its second argument, thus executing its
associated effects.

\subsubsection{Example 1. Addition}

To get acquainted with the proposed methodology, we start with a simple semantics for
the addition instruction, which will read the summands from the two locations, add them,
write the result into the third location and also update the state of the \hs{zero}
flag to indicate if the sum was zero:

\begin{minted}[xleftmargin=10pt]{haskell}
add :: Location -> Location -> Location -> ISA Value
add var1 var2 dest =
    let arg1     = read var1
        arg2     = read var2
        sum      = (+)  <$> arg1   <*> arg2
        isZero   = (==) <$> pure 0 <*> write dest sum
        overflow = willOverflowPure <$> arg1 <*> arg2
    in write "zero"     (fromBool <$> isZero) *>
       write "overflow" (fromBool <$> overflow)
\end{minted}

Here, we get two effectful values from the two locations and calculate three intermediate
results. To calculate the sum we just lift \hs{+} into the free selective using the applicative
combinators. We calculate the state of the \hs{"zero"} flag in the similar way, but here we
exploit the fact that the \hs{write} combinator returns the value it has just written, thus we
can reuse the value of the sum without recalculating it and triggering its associated effects
again. We detect integer overflow by means of a pure function, thus there is not much difference
with calculating the sum (\todo{discuss effects of \hs{willOverflow}?}).

The free selective functor construction shines in the static analysis. By executing
the analysis of the \hs{add} semantics, we can find obtain the list of all its effects:
\begin{minted}[xleftmargin=10pt]{haskell}
> analyse (add "x" "y" "z")
([],Left (W "overflow" :| [R "y",R "x",W "zero",W "z",R "y",R "x"]))
\end{minted}
If we read the list from right to left, we could see that \hs{add} read the values of the
arguments than written the destination variable then then something else \todo{write this}.

The addition instruction semantics has only used the applicative combinators and thus
the same analysis capabilities could have been implemented with free applicative functors.
However, there are important instructions whose semantics cannot be implemented in terms
of the \hs{Applicative} interface, but still do not require such heavy artillery as monads.

\subsubsection{Example 2. Conditional jump}

Selective functors allow to introduce limited dependencies between effectful computations.
It turns out, that they give just enough power to implement the semantics of conditional
jump instructions. A relative conditional jump offsets the program counter in case if a
certain condition, materialised in a microarchitectural flag, holds. For instance, some instruction set might have a jump triggered by the fact that the result of the last addition was zero

\begin{minted}[xleftmargin=10pt]{haskell}
jumpZero :: Value -> ISA ()
jumpZero offset =
    let pc       = read PC
        zeroSet  = (/=) <$> pure 0 <*> read (Flag Zero)
        modifyPC = void $ write PC (fmap (+ offset) pc)
    in whenS zeroSet modifyPC
\end{minted}

Here we use the aforementioned \hs{whenS} combinator to only execute the effect, i.e.
to modify the program counter, if the flag is set. By implementing this semantics in terms of
\hs{Selective} we achieve both the ability to implement an adequate simulator for the ISA and
to retain the possibilities for the static analysis of programs by means of the \hs{analyse} function:

\begin{minted}[xleftmargin=10pt]{haskell}
> analyse (jumpZero 42)
([],Left (Write PC :| [Read PC,Read Zero]))
\end{minted}

The \hs{analyse} function informs us of all necessary effects of the computation, thus
effectively giving us an over-approximated list of dependencies. Note that it does not matter
what argument we supply, since it will never get evaluated, e.g. the analysis will succeed and give us the same result even if we supply \hs{undefined}.

\subsubsection{Blocks of instructions}

